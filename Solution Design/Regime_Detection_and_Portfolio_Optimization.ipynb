{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MUgZzlMC-93e",
        "hrcc57ys-otM",
        "l7UZuAcK7V26",
        "1f-pKt2D9XiD",
        "0Ckb2HcZDAR3",
        "BV4_TURQHoYs",
        "AHK0YhNPOJv3"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inputs\n",
        "Stock symbos, Risk Preferences, and Risk-free rate"
      ],
      "metadata": {
        "id": "oGhkN95E-5jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the asset list in Thai stock market (Recommend at least 20 assets)\n",
        "# The example below is the list of stocks in SET100 index\n",
        "# Note: We will automatically added GLD: Gold ETF into this symbols\n",
        "symbols = [\n",
        "    \"AAV\", \"ADVANC\", \"AEONTS\", \"AMATA\", \"AOT\", \"AP\", \"AURA\", \"AWC\", \"BA\", \"BAM\",\n",
        "    \"BANPU\", \"BBL\", \"BCH\", \"BCP\", \"BCPG\", \"BDMS\", \"BEM\", \"BGRIM\", \"BH\", \"BJC\",\n",
        "    \"BLA\", \"BTG\", \"BTS\", \"CBG\", \"CCET\", \"CENTEL\", \"CHG\", \"CK\", \"COM7\", \"CPALL\",\n",
        "    \"CPF\", \"CPN\", \"CRC\", \"DELTA\", \"DOHOME\", \"EA\", \"EGCO\", \"ERW\", \"GFPT\", \"GLOBAL\",\n",
        "    \"GPSC\", \"GULF\", \"GUNKUL\", \"HANA\", \"HMPRO\", \"ICHI\", \"IRPC\", \"IVL\", \"JAS\", \"JMART\",\n",
        "    \"JMT\", \"JTS\", \"KBANK\", \"KCE\", \"KKP\", \"KTB\", \"KTC\", \"LH\", \"M\", \"MEGA\", \"MINT\",\n",
        "    \"MOSHI\", \"MTC\", \"OR\", \"OSP\", \"PLANB\", \"PR9\", \"PRM\", \"PTG\", \"PTT\", \"PTTEP\",\n",
        "    \"PTTGC\", \"QH\", \"RATCH\", \"RCL\", \"SAWAD\", \"SCB\", \"SCC\", \"SCGP\", \"SIRI\", \"SISB\",\n",
        "    \"SJWD\", \"SPALI\", \"SPRC\", \"STA\", \"STECON\", \"STGT\", \"TASCO\", \"TCAP\", \"TFG\",\n",
        "    \"TIDLOR\", \"TISCO\", \"TLI\", \"TOA\", \"TOP\", \"TRUE\", \"TTB\", \"TU\", \"VGI\", \"WHA\"\n",
        "]"
      ],
      "metadata": {
        "id": "_M52_op6-XLp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the risk-free rate (Assuming cash deposit with broker give interest at 0.5% per annum)\n",
        "risk_free_rate = 0.005 # 0.5%"
      ],
      "metadata": {
        "id": "ydd0bAOGN80e"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference mapping:\n",
        "# 0: sideways : set lambda = 1\n",
        "# 1: Bears: set lambda = 2 (greater than 1)\n",
        "# 2: Bull set lambda as 0.5 (less than 1)\n",
        "\n",
        "lambda_map = {0: 1, 1: 2, 2: 0.5}"
      ],
      "metadata": {
        "id": "VPZ72ozmKsTP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process: Algorithm"
      ],
      "metadata": {
        "id": "MUgZzlMC-93e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Capture the start time for the entire optimization and output process\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "KMkso-grPqu-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "hrcc57ys-otM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "M2s4_mvG3s0k"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import cvxpy as cvx\n",
        "from sklearn.covariance import LedoitWolf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Trained Models"
      ],
      "metadata": {
        "id": "l7UZuAcK7V26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GitHub raw URL for the trained models\n",
        "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/adisorn242/2026_WQU_CapstoneProject/main/Trained%20Models\"\n",
        "\n",
        "model_files = [\n",
        "    'scaler.joblib',\n",
        "    'base_lr.joblib',\n",
        "    'base_xgb.joblib',\n",
        "    'base_svm.joblib',\n",
        "    'base_rf.joblib',\n",
        "    'base_dnn.keras',\n",
        "    'meta_learner.joblib'\n",
        "]\n",
        "\n",
        "# Download missing files to the local Colab environment\n",
        "for file in model_files:\n",
        "    if not os.path.exists(file):\n",
        "        url = f\"{GITHUB_RAW_URL}/{file}\".replace(\" \", \"%20\")\n",
        "        os.system(f\"wget {url}\")\n",
        "\n",
        "# Load preprocessing and Scikit-Learn/XGBoost components\n",
        "scaler = joblib.load('scaler.joblib')\n",
        "base_lr = joblib.load('base_lr.joblib')\n",
        "base_xgb = joblib.load('base_xgb.joblib')\n",
        "base_svm = joblib.load('base_svm.joblib')\n",
        "base_rf = joblib.load('base_rf.joblib')\n",
        "meta_learner = joblib.load('meta_learner.joblib')\n",
        "\n",
        "# Load the DNN model with compile=False to prevent optimizer variable warnings.\n",
        "# The optimizer is only needed for training; for prediction, we only need the weights.\n",
        "base_dnn = tf.keras.models.load_model('base_dnn.keras', compile=False)"
      ],
      "metadata": {
        "id": "50adwWI07XtX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def voter_predict(X_scaled):\n",
        "    \"\"\"\n",
        "    Manual implementation of the Soft Voting (Majority Voter) logic.\n",
        "    Calculates the average probability across all 5 base learners and\n",
        "    applies a 0.5 threshold to determine the market regime.\n",
        "    \"\"\"\n",
        "    # Extract probabilities for the positive class (Regime 1) from Scikit-Learn/XGB models\n",
        "    p1 = base_lr.predict_proba(X_scaled)[:, 1]\n",
        "    p2 = base_xgb.predict_proba(X_scaled)[:, 1]\n",
        "    p3 = base_svm.predict_proba(X_scaled)[:, 1]\n",
        "    p4 = base_rf.predict_proba(X_scaled)[:, 1]\n",
        "\n",
        "    # DNN returns the probability directly for binary classification\n",
        "    p5 = base_dnn.predict(X_scaled, verbose=0).flatten()\n",
        "\n",
        "    # Compute the arithmetic mean of all model probabilities\n",
        "    avg_prob = (p1 + p2 + p3 + p4 + p5) / 5\n",
        "\n",
        "    # Return binary classification (1 for Bull/High Volatility, 0 for Bear/Low Volatility)\n",
        "    return (avg_prob >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "OIIAAIOq7yff"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Stock and Index data"
      ],
      "metadata": {
        "id": "1f-pKt2D9XiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the asset list in Thai stock market (Recommend at least 20 assets)\n",
        "# The example below is the list of stocks in SET100 index\n",
        "# Note: We will automatically added GLD: Gold ETF into this symbols\n",
        "# [List of symbols provided above...]\n",
        "\n",
        "# Add Gold ETF to the list\n",
        "if \"GLD\" not in symbols:\n",
        "    symbols.append(\"GLD\")\n",
        "\n",
        "# Format tickers for Yahoo Finance using the .BK suffix\n",
        "all_tickers = [s + \".BK\" for s in symbols]\n",
        "\n",
        "# Calculate date range for exactly 105 weeks\n",
        "# Enough thinking\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(weeks=105)\n",
        "\n",
        "# Fetch weekly data\n",
        "# interval=\"1wk\" captures weekly candles\n",
        "# auto_adjust=True handles corporate actions for price consistency\n",
        "# multi_level_index=False flattens the column headers for direct indexing\n",
        "data = yf.download(\n",
        "    all_tickers,\n",
        "    start=start_date.strftime('%Y-%m-%d'),\n",
        "    end=end_date.strftime('%Y-%m-%d'),\n",
        "    interval=\"1wk\",\n",
        "    auto_adjust=True,\n",
        "    progress=False,\n",
        "    multi_level_index=False\n",
        ")\n",
        "\n",
        "# Extract Open and Close prices; .tail(105) ensures the total count is exactly 105\n",
        "df_all_open = data['Open'].tail(105)\n",
        "df_all_close = data['Close'].tail(105)\n",
        "\n",
        "# Compute Simple Return: (Close / Open) - 1\n",
        "df_asset_returns = (df_all_close / df_all_open) - 1\n",
        "\n",
        "# Integrate the Risk-Free Asset (Must be named 'RiskFree_Rate' for the MVO function)\n",
        "# risk_free_rate = 0.005 (0.5% per annum)\n",
        "rf_weekly = risk_free_rate / 52\n",
        "df_asset_returns['RiskFree_Rate'] = rf_weekly\n",
        "\n",
        "print(f\"Captured {len(df_all_close)} weeks.\")\n",
        "print(f\"Total Assets (including Gold and RiskFree_Rate): {len(df_asset_returns.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYlYGdrU9YrF",
        "outputId": "b238bc21-9740-4459-9d87-839abfbe82eb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captured 105 weeks.\n",
            "Total Assets (including Gold and RiskFree_Rate): 102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-291614600.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_asset_returns['RiskFree_Rate'] = rf_weekly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SET Index data using the pre-defined date range\n",
        "# The ^SET.BK ticker represents the benchmark index for the Stock Exchange of Thailand\n",
        "df_set_index = yf.download(\n",
        "    \"^SET.BK\",\n",
        "    start=start_date.strftime('%Y-%m-%d'),\n",
        "    end=end_date.strftime('%Y-%m-%d'),\n",
        "    interval=\"1wk\",\n",
        "    auto_adjust=True,\n",
        "    progress=False,\n",
        "    multi_level_index=False\n",
        ")\n",
        "\n",
        "# Align the index data with the asset data by taking the last 105 weeks\n",
        "# This ensures consistency for feature engineering and regime detection\n",
        "df_set_index = df_set_index.tail(105)\n",
        "\n",
        "print(f\"SET Index data ready: {len(df_set_index)} weeks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uZkXLBr_sna",
        "outputId": "f8852776-8d74-4756-ec7e-68cbc77a9f61"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SET Index data ready: 105 weeks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "0Ckb2HcZDAR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the weekly simple returns for the SET100 constituents\n",
        "# Formula: (Close / Open) - 1\n",
        "df_asset_returns = (df_all_close / df_all_open) - 1\n",
        "\n",
        "# Check for any missing values and verify shape\n",
        "print(f\"Simple returns calculated. Shape: {df_asset_returns.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y57zXqlmBhIc",
        "outputId": "2af8ff59-cc76-44f7-8458-194d81cee81d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple returns calculated. Shape: (105, 101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare SET features for model prediction\n",
        "\n",
        "# 1. Initialize the feature dataframe with the current weekly log return as 'lag1'\n",
        "# This is named 'SET_log_ret_lag1' to match the training schema\n",
        "df_SET_features = np.log(df_set_index['Close'] / df_set_index['Open']).to_frame(name='SET_log_ret_lag1')\n",
        "\n",
        "# 2. Calculate Open-to-High and Open-to-Low log returns for the current period\n",
        "# Note: Renamed to include '_lag1' to match the feature names seen at fit time\n",
        "df_SET_features['SET_OH_log_ret_lag1'] = np.log(df_set_index['High'] / df_set_index['Open'])\n",
        "df_SET_features['SET_OL_log_ret_lag1'] = np.log(df_set_index['Low'] / df_set_index['Open'])\n",
        "\n",
        "# 3. Generate Lag 2 up to Lag 52 based on the 'SET_log_ret_lag1' column\n",
        "for i in range(2, 53):\n",
        "    df_SET_features[f'SET_log_ret_lag{i}'] = df_SET_features['SET_log_ret_lag1'].shift(i-1)\n",
        "\n",
        "# --- Add technical analysis indicators ---\n",
        "\n",
        "# 1. MACD (12, 26, 9)\n",
        "ema_12 = df_set_index['Close'].ewm(span=12, adjust=False, min_periods=12).mean()\n",
        "ema_26 = df_set_index['Close'].ewm(span=26, adjust=False, min_periods=26).mean()\n",
        "macd_line = ema_12 - ema_26\n",
        "macd_histogram = macd_line - macd_line.ewm(span=9, adjust=False, min_periods=9).mean()\n",
        "\n",
        "# 2. RSI (14-period Wilder's)\n",
        "delta = df_set_index['Close'].diff()\n",
        "gain = delta.where(delta > 0, 0)\n",
        "loss = -delta.where(delta < 0, 0)\n",
        "avg_gain = gain.ewm(alpha=1/14, min_periods=14, adjust=False).mean()\n",
        "avg_loss = loss.ewm(alpha=1/14, min_periods=14, adjust=False).mean()\n",
        "rsi = 100 - (100 / (1 + (avg_gain / avg_loss)))\n",
        "\n",
        "# 3. Money Flow Index (MFI - 14-period)\n",
        "tp = (df_set_index['High'] + df_set_index['Low'] + df_set_index['Close']) / 3\n",
        "mf = tp * df_set_index['Volume']\n",
        "pos_f = (mf.where(tp > tp.shift(1), 0)).rolling(window=14, min_periods=14).sum()\n",
        "neg_f = (mf.where(tp < tp.shift(1), 0)).rolling(window=14, min_periods=14).sum()\n",
        "mfi = 100 - (100 / (1 + (pos_f / neg_f)))\n",
        "\n",
        "# 4. Average True Range (ATR - 14-period)\n",
        "tr = pd.concat([df_set_index['High'] - df_set_index['Low'],\n",
        "                abs(df_set_index['High'] - df_set_index['Close'].shift(1)),\n",
        "                abs(df_set_index['Low'] - df_set_index['Close'].shift(1))], axis=1).max(axis=1)\n",
        "atr = tr.rolling(window=14, min_periods=14).mean()\n",
        "\n",
        "# 5. On-Balance Volume (OBV)\n",
        "obv = (np.sign(df_set_index['Close'].diff()) * df_set_index['Volume']).fillna(0).cumsum()\n",
        "\n",
        "# 6. Lagging and Merging (No dropping)\n",
        "df_temp_ta_raw = pd.DataFrame(index=df_set_index.index)\n",
        "ta_data = {\n",
        "    'SET_MACD_lag_1': macd_line,\n",
        "    'SET_MACD_Hist_lag_1': macd_histogram,\n",
        "    'SET_RSI_lag_1': rsi,\n",
        "    'SET_MFI_lag_1': mfi,\n",
        "    'SET_ATR_lag_1': atr,\n",
        "    'SET_OBV_lag_1': obv\n",
        "}\n",
        "\n",
        "for col_name, data_series in ta_data.items():\n",
        "    df_temp_ta_raw[col_name] = data_series.shift(1)\n",
        "\n",
        "# Join the dataframes without dropping NA rows\n",
        "df_SET_features = df_SET_features.join(df_temp_ta_raw)\n",
        "\n",
        "# 7. Isolate and Normalize/Scale the last row for prediction\n",
        "# We use the final row representing the latest state\n",
        "latest_row = df_SET_features.tail(1)\n",
        "\n",
        "# Ensure the column order matches exactly what the scaler expects\n",
        "# (Optional but recommended if the order might have shifted)\n",
        "latest_row = latest_row[scaler.feature_names_in_]\n",
        "\n",
        "# Scale the feature vector using the pre-fitted scaler\n",
        "X_latest_scaled = scaler.transform(latest_row)\n",
        "\n",
        "print(\"Feature engineering complete. Last row isolated and scaled.\")\n",
        "print(f\"Scaled feature vector shape: {X_latest_scaled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxK8W7kUDWGN",
        "outputId": "25d5097e-ab7e-41a0-e41b-27c22abb875e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering complete. Last row isolated and scaled.\n",
            "Scaled feature vector shape: (1, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regime Detection for next period"
      ],
      "metadata": {
        "id": "BV4_TURQHoYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the list of base learners\n",
        "base_learners = [base_lr, base_xgb, base_svm, base_rf, base_dnn]\n",
        "\n",
        "# 2. Convert X_latest_scaled back to a DataFrame to satisfy the \"feature names\" requirement\n",
        "# We use the feature names from the scaler to ensure an exact match\n",
        "X_latest_df = pd.DataFrame(X_latest_scaled, columns=scaler.feature_names_in_)\n",
        "\n",
        "# 3. Generate Meta-Features\n",
        "base_preds = []\n",
        "\n",
        "for model in base_learners:\n",
        "    if model == base_dnn:\n",
        "        # Keras doesn't care about feature names in the same way, but we pass the array\n",
        "        pred = model.predict(X_latest_scaled, verbose=0)\n",
        "    else:\n",
        "        # Pass the DataFrame (X_latest_df) to resolve the UserWarning\n",
        "        pred = model.predict_proba(X_latest_df)\n",
        "\n",
        "    base_preds.append(pred)\n",
        "\n",
        "# Combine base predictions into the meta-feature vector\n",
        "meta_features = np.hstack(base_preds)\n",
        "\n",
        "# 4. Stacking Prediction (Meta-Learning)\n",
        "# Note: The meta_learner was likely trained on a raw array of probabilities,\n",
        "# so we pass the meta_features array directly here.\n",
        "regime_stacking = meta_learner.predict(meta_features)[0]\n",
        "prob_stacking = meta_learner.predict_proba(meta_features)[0]\n",
        "\n",
        "# 5. Voting Prediction (Soft Voting)\n",
        "avg_probabilities = np.mean(base_preds, axis=0)\n",
        "regime_voting = np.argmax(avg_probabilities)\n",
        "prob_voting = avg_probabilities[0]\n",
        "\n",
        "# Store results\n",
        "prediction_results = {\n",
        "    \"stacking\": {\"regime\": regime_stacking, \"probability\": prob_stacking},\n",
        "    \"voting\": {\"regime\": regime_voting, \"probability\": prob_voting}\n",
        "}\n",
        "\n",
        "print(f\"Stacking Regime: {regime_stacking} (Confidence: {max(prob_stacking)*100:.2f}%)\")\n",
        "print(f\"Voting Regime:   {regime_voting} (Confidence: {max(prob_voting)*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XemBBHFfHUgg",
        "outputId": "e3604074-6a74-4534-c311-b69f321e8319"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Regime: 2 (Confidence: 90.93%)\n",
            "Voting Regime:   2 (Confidence: 45.99%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Portfolio Optimization"
      ],
      "metadata": {
        "id": "RaFZhDdEI9_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dynamic_mvo_weights(window_ret, lambda_val, regime):\n",
        "    \"\"\"\n",
        "    Finalized Strategic Logic:\n",
        "    - Regime 1 (Bear): Gold <= 20%, TOTAL Stocks <= 10%, Risk-Free takes remainder (min 70%).\n",
        "    - Regime 2 (Bull): Gold <= 5%, Risk-Free <= 5%, Individual Stocks <= 10% (High Conviction).\n",
        "    - Regime 0 (Neutral): all Assets (Stocks/Gold) <= 5%, Risk-Free <= 100%.\n",
        "    \"\"\"\n",
        "    # 1. Ensure regime is an integer\n",
        "    regime = int(regime)\n",
        "\n",
        "    # 2. Data Preparation\n",
        "    clean_window = window_ret.dropna(axis=1)\n",
        "    assets = clean_window.columns.tolist()\n",
        "    n = len(assets)\n",
        "\n",
        "    if n == 0:\n",
        "        return np.zeros(len(window_ret.columns))\n",
        "\n",
        "    # 3. Calculate Mean and Ledoit-Wolf Shrunk Covariance\n",
        "    mu = clean_window.mean().values\n",
        "    lw = LedoitWolf()\n",
        "    Sigma_shrunk = lw.fit(clean_window).covariance_\n",
        "\n",
        "    # 4. Variables and Base Constraints\n",
        "    w = cvx.Variable(n)\n",
        "    constraints = [cvx.sum(w) == 1, w >= 0]\n",
        "\n",
        "    # Identify indices for stocks\n",
        "    stock_indices = [i for i, name in enumerate(assets) if name not in ['GLD.BK', 'RiskFree_Rate']]\n",
        "\n",
        "    # 5. Define Regime-Specific Constraints\n",
        "    for i, asset_name in enumerate(assets):\n",
        "        if regime == 1:  # --- BEAR MARKET ---\n",
        "            if asset_name == 'GLD.BK':\n",
        "                constraints.append(w[i] <= 0.20)  # Gold cap 20%\n",
        "            elif asset_name == 'RiskFree_Rate':\n",
        "                constraints.append(w[i] <= 1.00)\n",
        "            else:\n",
        "                constraints.append(w[i] <= 0.05)  # Individual stock cap\n",
        "\n",
        "        elif regime == 2:  # --- BULL MARKET ---\n",
        "            if asset_name == 'GLD.BK' or asset_name == 'RiskFree_Rate':\n",
        "                constraints.append(w[i] <= 0.05)  # Defensive limited to 5%\n",
        "            else:\n",
        "                constraints.append(w[i] <= 0.10)  # High conviction stock cap\n",
        "\n",
        "        else:  # --- NEUTRAL MARKET ---\n",
        "            if asset_name == 'RiskFree_Rate':\n",
        "                constraints.append(w[i] <= 1.00)  # Cash remains the flexible buffer\n",
        "            else:\n",
        "                # Gold and Stocks are treated equally here (max 5% each)\n",
        "                constraints.append(w[i] <= 0.05)\n",
        "\n",
        "    # 6. Apply TOTAL Stock Constraint specifically for BEAR Market\n",
        "    if regime == 1 and len(stock_indices) > 0:\n",
        "        constraints.append(cvx.sum(w[stock_indices]) <= 0.10)\n",
        "\n",
        "    # 7. Objective: Maximize Risk-Adjusted Utility\n",
        "    # Using psd_wrap to ensure CVXPY recognizes Sigma as Positive Semi-Definite\n",
        "    risk = cvx.quad_form(w, cvx.psd_wrap(Sigma_shrunk))\n",
        "    objective = cvx.Maximize(mu @ w - 0.5 * lambda_val * risk)\n",
        "\n",
        "    # 8. Solve using OSQP solver\n",
        "    prob = cvx.Problem(objective, constraints)\n",
        "    prob.solve(solver=cvx.OSQP)\n",
        "\n",
        "    # 9. Map weights back to the original stock list (filling 0 for dropped NAs)\n",
        "    final_weights = pd.Series(0.0, index=window_ret.columns)\n",
        "    if w.value is not None:\n",
        "        final_weights[assets] = w.value\n",
        "\n",
        "    return final_weights.values"
      ],
      "metadata": {
        "id": "SoaIAAZxH685"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Extract predicted regimes from the ensemble results\n",
        "regime_s = prediction_results[\"stacking\"][\"regime\"]\n",
        "regime_v = prediction_results[\"voting\"][\"regime\"]\n",
        "\n",
        "# 2. Calculate optimal weights for the Stacking Regime\n",
        "# Uses the lambda_map defined in the previous input block\n",
        "weights_stacking = get_dynamic_mvo_weights(\n",
        "    window_ret=df_asset_returns,\n",
        "    lambda_val=lambda_map[regime_s],\n",
        "    regime=regime_s\n",
        ")\n",
        "\n",
        "# 3. Calculate optimal weights for the Voting Regime\n",
        "weights_voting = get_dynamic_mvo_weights(\n",
        "    window_ret=df_asset_returns,\n",
        "    lambda_val=lambda_map[regime_v],\n",
        "    regime=regime_v\n",
        ")\n",
        "\n",
        "# 4. Consolidate into a final DataFrame\n",
        "df_final_weights = pd.DataFrame({\n",
        "    'Stacking_Weight': weights_stacking,\n",
        "    'Voting_Weight': weights_voting\n",
        "}, index=df_asset_returns.columns)"
      ],
      "metadata": {
        "id": "0vlx4NPgNZ6D"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output\n",
        "Optimal Asset Weights"
      ],
      "metadata": {
        "id": "AHK0YhNPOJv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Capture end time and calculate duration\n",
        "end_time = time.time()\n",
        "total_duration = end_time - start_time\n",
        "\n",
        "# 2. Define descriptive names for regimes\n",
        "regime_names = {0: \"Sideways\", 1: \"Bear\", 2: \"Bull\"}\n",
        "\n",
        "# 3. Preparation of results for display\n",
        "regime_s = prediction_results[\"stacking\"][\"regime\"]\n",
        "regime_v = prediction_results[\"voting\"][\"regime\"]\n",
        "prob_s = np.max(prediction_results[\"stacking\"][\"probability\"])\n",
        "prob_v = np.max(prediction_results[\"voting\"][\"probability\"])\n",
        "\n",
        "# 4. Print Configuration and Parameters\n",
        "print(\"=\"*65)\n",
        "print(f\"{'STRATEGY CONFIGURATION & PARAMETERS':^65}\")\n",
        "print(\"=\"*65)\n",
        "print(f\"Risk Aversion Mapping (lambda_map):\")\n",
        "for r_code, l_val in lambda_map.items():\n",
        "    print(f\"  - Regime {r_code} ({regime_names[r_code]:8}): lambda = {l_val}\")\n",
        "\n",
        "print(f\"\\nRisk-Free Rate (Annual): {risk_free_rate:.2%}\")\n",
        "print(f\"Risk-Free Rate (Weekly): {(risk_free_rate/52):.6%}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "# 5. Print Model Predictions\n",
        "print(f\"{'MARKET REGIME PREDICTIONS':^65}\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"STACKING MODEL: Regime {regime_s} ({regime_names[regime_s]}) | Conf: {prob_s:.2%}\")\n",
        "print(f\"VOTING MODEL:   Regime {regime_v} ({regime_names[regime_v]}) | Conf: {prob_v:.2%}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "# 6. Filter and format the Weight DataFrame\n",
        "df_output = df_final_weights[(df_final_weights['Stacking_Weight'] > 0.0001) |\n",
        "                             (df_final_weights['Voting_Weight'] > 0.0001)].copy()\n",
        "df_output = df_output.sort_values(by='Stacking_Weight', ascending=False)\n",
        "\n",
        "print(f\"Active Portfolio Weights ({len(df_output)} Assets):\")\n",
        "display(df_output.style.format({\n",
        "    'Stacking_Weight': '{:.2%}',\n",
        "    'Voting_Weight': '{:.2%}'\n",
        "}))\n",
        "\n",
        "# 7. Final Validation and Timing\n",
        "print(\"-\" * 65)\n",
        "print(f\"Total Portfolio Weight (Stacking): {df_final_weights['Stacking_Weight'].sum():.2%}\")\n",
        "print(f\"Total Portfolio Weight (Voting):   {df_final_weights['Voting_Weight'].sum():.2%}\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"TOTAL EXECUTION TIME: {total_duration:.2f} seconds\")\n",
        "print(\"=\"*65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "XboCBCzmOJHy",
        "outputId": "501b1e74-25ad-4205-f2dd-a23d7d5a5e54"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "               STRATEGY CONFIGURATION & PARAMETERS               \n",
            "=================================================================\n",
            "Risk Aversion Mapping (lambda_map):\n",
            "  - Regime 0 (Sideways): lambda = 1\n",
            "  - Regime 1 (Bear    ): lambda = 2\n",
            "  - Regime 2 (Bull    ): lambda = 0.5\n",
            "\n",
            "Risk-Free Rate (Annual): 0.50%\n",
            "Risk-Free Rate (Weekly): 0.009615%\n",
            "-----------------------------------------------------------------\n",
            "                    MARKET REGIME PREDICTIONS                    \n",
            "-----------------------------------------------------------------\n",
            "STACKING MODEL: Regime 2 (Bull) | Conf: 90.93%\n",
            "VOTING MODEL:   Regime 2 (Bull) | Conf: 45.99%\n",
            "-----------------------------------------------------------------\n",
            "Active Portfolio Weights (11 Assets):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7babcc7a0380>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_5e55a\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_5e55a_level0_col0\" class=\"col_heading level0 col0\" >Stacking_Weight</th>\n",
              "      <th id=\"T_5e55a_level0_col1\" class=\"col_heading level0 col1\" >Voting_Weight</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Ticker</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row0\" class=\"row_heading level0 row0\" >ADVANC.BK</th>\n",
              "      <td id=\"T_5e55a_row0_col0\" class=\"data row0 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row0_col1\" class=\"data row0 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row1\" class=\"row_heading level0 row1\" >CCET.BK</th>\n",
              "      <td id=\"T_5e55a_row1_col0\" class=\"data row1 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row1_col1\" class=\"data row1 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row2\" class=\"row_heading level0 row2\" >DELTA.BK</th>\n",
              "      <td id=\"T_5e55a_row2_col0\" class=\"data row2 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row2_col1\" class=\"data row2 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row3\" class=\"row_heading level0 row3\" >KBANK.BK</th>\n",
              "      <td id=\"T_5e55a_row3_col0\" class=\"data row3 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row3_col1\" class=\"data row3 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row4\" class=\"row_heading level0 row4\" >KKP.BK</th>\n",
              "      <td id=\"T_5e55a_row4_col0\" class=\"data row4 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row4_col1\" class=\"data row4 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row5\" class=\"row_heading level0 row5\" >KTB.BK</th>\n",
              "      <td id=\"T_5e55a_row5_col0\" class=\"data row5 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row5_col1\" class=\"data row5 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row6\" class=\"row_heading level0 row6\" >STGT.BK</th>\n",
              "      <td id=\"T_5e55a_row6_col0\" class=\"data row6 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row6_col1\" class=\"data row6 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row7\" class=\"row_heading level0 row7\" >TRUE.BK</th>\n",
              "      <td id=\"T_5e55a_row7_col0\" class=\"data row7 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row7_col1\" class=\"data row7 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row8\" class=\"row_heading level0 row8\" >TFG.BK</th>\n",
              "      <td id=\"T_5e55a_row8_col0\" class=\"data row8 col0\" >10.00%</td>\n",
              "      <td id=\"T_5e55a_row8_col1\" class=\"data row8 col1\" >10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row9\" class=\"row_heading level0 row9\" >SCB.BK</th>\n",
              "      <td id=\"T_5e55a_row9_col0\" class=\"data row9 col0\" >5.00%</td>\n",
              "      <td id=\"T_5e55a_row9_col1\" class=\"data row9 col1\" >5.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5e55a_level0_row10\" class=\"row_heading level0 row10\" >GLD.BK</th>\n",
              "      <td id=\"T_5e55a_row10_col0\" class=\"data row10 col0\" >5.00%</td>\n",
              "      <td id=\"T_5e55a_row10_col1\" class=\"data row10 col1\" >5.00%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Total Portfolio Weight (Stacking): 100.00%\n",
            "Total Portfolio Weight (Voting):   100.00%\n",
            "-----------------------------------------------------------------\n",
            "TOTAL EXECUTION TIME: 5.16 seconds\n",
            "=================================================================\n"
          ]
        }
      ]
    }
  ]
}